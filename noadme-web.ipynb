{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README? NoADME!\n",
    "\n",
    "## Overview\n",
    "\n",
    "A concept figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU gradio python-dotenv langchain-upstage\n",
    "! pip install -qU markdown\n",
    "! pip install -qU requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# set UPSTAGE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# NoREADME 시스템 설명\\n\\n## 개요\\nNoREADME는 개발자가 GitHub 저장소에 있는 Markdown(md) 파일을 자동으로 분석하고, Mermaid 다이어그램을 생성하여 해당 파일에 추가하는 시스템입니다. 이 시스템은 LangChain 파이프라인을 사용하여 파일을 다운로드하고 분석하며, 엔티티 및 인터랙션을 추출한 후, Mermaid 다이어그램을 생성합니다. 생성된 다이어그램은 GitHub에 커밋되어 사용자가 직접 작성하는 번거로움을 줄여줍니다.\\n\\n## 기능\\n1. **사용자 입력**:\\n    - 사용자는 NoREADME 웹 인터페이스를 통해 GitHub md 파일 URL을 입력합니다.\\n\\n2. **파일 다운로드**:\\n    - NoREADME 서버는 입력된 URL을 받아 LangChain 파이프라인을 시작합니다.\\n    - 파일 다운로드 스테이지가 URL을 통해 md 파일을 GitHub에서 다운로드합니다.\\n\\n3. **컨텍스트 검색 및 텍스트 분석**:\\n    - 다운로드된 파일 콘텐츠는 컨텍스트 검색기와 텍스트 분석 스테이지를 통해 분석됩니다.\\n    - 관련 컨텍스트를 검색하고 파일 콘텐츠를 분석하여 엔티티와 인터랙션을 추출합니다.\\n\\n4. **Mermaid 다이어그램 생성**:\\n    - 추출된 엔티티와 인터랙션을 기반으로 Mermaid 다이어그램 생성기가 다이어그램을 생성합니다.\\n    - 생성된 다이어그램은 검증기를 통해 검증됩니다.\\n\\n5. **GitHub에 커밋**:\\n    - 최종적으로 NoREADME 서버는 생성된 다이어그램을 원본 md 파일에 추가하고, GitHub에 커밋합니다.\\n    - 업데이트된 파일은 사용자가 확인할 수 있습니다.\\n\\n\\n## 설명\\n\\n1. **사용자 입력**:\\n    - 사용자가 NoREADME 웹에 GitHub md 파일 URL을 입력합니다.\\n    - 웹 애플리케이션이 이 URL을 NoREADME 서버로 전송합니다.\\n\\n2. **파일 다운로드 및 분석**:\\n    - 서버가 LangChain 파이프라인을 시작합니다.\\n    - URL 입력 스테이지가 URL을 받고 반환합니다.\\n    - 파일 다운로드 스테이지가 GitHub에서 md 파일을 요청하고 다운로드합니다.\\n\\n3. **컨텍스트 검색 및 텍스트 분석**:\\n    - 다운로드된 파일 콘텐츠를 LangChain 파이프라인에 전달합니다.\\n    - 컨텍스트 검색기가 관련 컨텍스트를 검색하여 반환합니다.\\n    - 텍스트 분석 스테이지가 파일 콘텐츠와 컨텍스트를 분석하여 추출된 컨텍스트를 반환합니다.\\n\\n4. **엔티티 및 인터랙션 추출**:\\n    - 엔티티 추출 스테이지가 파일에서 엔티티와 상호작용을 추출하여 반환합니다.\\n\\n5. **Mermaid 다이어그램 생성**:\\n    - Mermaid 다이어그램 생성기가 추출된 엔티티와 상호작용을 기반으로 다이어그램을 생성하고 반환합니다.\\n\\n6. **다이어그램 검증**:\\n    - 검증기가 생성된 다이어그램을 검증하고 결과를 반환합니다.\\n\\n7. **GitHub에 커밋**:\\n    - 최종적으로 NoREADME 서버가 GitHub에 다이어그램을 커밋합니다.\\n    - 업데이트된 md 파일이 사용자에게 반환됩니다.\\n\\n이 시스템은 개발자가 반복적으로 README.md 파일을 작성하는 번거로움을 줄여주어 효율적인 작업 환경을 제공합니다.\\n\\n[NoREADME_sequence_diagram.md 파일 다운로드](sandbox:/mnt/data/AutoMermaid_sequence_diagram.md)\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import requests\n",
    "# import markdown\n",
    "\n",
    "# def fetch_github_readme(readme_raw_url):\n",
    "\n",
    "#     # Fetch the README.md file content\n",
    "#     response = requests.get(readme_raw_url)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.text\n",
    "#     else:\n",
    "#         return f\"Error fetching README.md file: {response.status_code}\"\n",
    "    \n",
    "# # Example usage\n",
    "# repo_url = \"https://raw.githubusercontent.com/noadme/noadme/main/test/test01.md\"  # Replace with your GitHub repo URL\n",
    "# readme = fetch_github_readme(repo_url)\n",
    "# readme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-shot prompt to get mermaid syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_upstage import ChatUpstage\n",
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "smsg = \"\"\"You are a helpful assistant. Please extract user and participants's name  from the following text. I am a user. Then, organize the action relationships between me and the participants.\n",
    "---\n",
    "    We are a team of 5 members called Krispy Team.\n",
    "    Dr. Kim Yoon-gon gave me coffee. I said thank you.\n",
    "    Student Jae-min also received coffee from Dr. Kim Yoon-gon. Dr. Son Seok-ho is explaining the team project topic now.\n",
    "    Student Sung-hoon is preparing presentation materials for other team members.\n",
    "\n",
    "    This is an answer template\n",
    "    ```mermaid\n",
    "    sequenceDiagram\n",
    "        actor User\n",
    "        participant Kim Yoon-gon\n",
    "        participant Jae-min\n",
    "        participant Son Seok-ho\n",
    "        participant Sung-hoon\n",
    "        participant Other team members\n",
    "\n",
    "        User ->> Kim Yoon-gon : Received coffee and said thank you\n",
    "        Kim Yoon-gon ->> Jae-min : Gave coffee\n",
    "        Son Seok-ho ->> Team : Explained the project topic\n",
    "        Sung-hoon ->> Other team members : Prepared presentation materials\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", smsg),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{message}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain_upstage import ChatUpstage\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt_template = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     Q: Please extract user and participants's name  from the following text. I am a user. Then, organize the action relationships between me and the participants. \n",
    "\n",
    "#     ---\n",
    "#     We are a team of 5 members called Krispy Team.\n",
    "#     Dr. Kim Yoon-gon gave me coffee. I said thank you.\n",
    "#     Student Jae-min also received coffee from Dr. Kim Yoon-gon. Dr. Son Seok-ho is explaining the team project topic now.\n",
    "#     Student Sung-hoon is preparing presentation materials for other team members.\n",
    "\n",
    "#     A:\n",
    "#     ```mermaid\n",
    "#     sequenceDiagram\n",
    "#         actor User\n",
    "#         participant Kim Yoon-gon\n",
    "#         participant Jae-min\n",
    "#         participant Son Seok-ho\n",
    "#         participant Sung-hoon\n",
    "#         participant Other team members\n",
    "\n",
    "#         User ->> Kim Yoon-gon : Received coffee and said thank you\n",
    "#         Kim Yoon-gon ->> Jae-min : Gave coffee\n",
    "#         Son Seok-ho ->> Team : Explained the project topic\n",
    "#         Sung-hoon ->> Other team members : Prepared presentation materials\n",
    "#     ```\n",
    "\n",
    "#     Q: Please extract the user's name and participants' names from the following text. The user is the person who is writing this prompt. Then, organize the action relationships between the user and the participants into a sequence diagram using mermaid syntax.\n",
    "\n",
    "#     ---\n",
    "#     {text}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# llm = ChatUpstage()\n",
    "# chain = prompt_template | llm | StrOutputParser()\n",
    "# # content = \"We are a team of four.I am currently creating a template to give to Dr. Kim Yoon-gon.Also, Student Sung-hoon is creating an RAG to give to Dr. Kim Yoon-gon. The other two members are discussing ideas with each other.\"\n",
    "# answer = chain.invoke({\"text\": readme})\n",
    "# print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# GitHub Personal Access Token 및 사용자/저장소 정보 설정\n",
    "GITHUB_TOKEN = os.environ[\"GITHUB_TOKEN\"]\n",
    "REPO_OWNER = os.environ[\"REPO_OWNER\"]\n",
    "REPO_NAME = os.environ[\"REPO_NAME\"]\n",
    "\n",
    "# 파일 경로 및 내용 설정\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "file_path = f\"test/test-result-{timestamp}.md\"\n",
    "\n",
    "# GitHub API URL 설정\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "\n",
    "# 헤더 설정\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "\n",
    "# 1. 브랜치 생성 함수\n",
    "def create_branch(branch_name):\n",
    "    # main 브랜치의 최신 커밋 SHA 가져오기\n",
    "    response = requests.get(f\"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/git/ref/heads/main\", headers=headers)\n",
    "    sha = response.json()[\"object\"][\"sha\"]\n",
    "\n",
    "    # 새 브랜치 생성\n",
    "    data = {\n",
    "        \"ref\": f\"refs/heads/{branch_name}\",\n",
    "        \"sha\": sha\n",
    "    }\n",
    "    response = requests.post(f\"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/git/refs\", headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 201:\n",
    "        print(f\"Branch '{branch_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to create branch: {response.json()}\")\n",
    "\n",
    "# 2. 파일 커밋 함수\n",
    "def commit_file(branch_name, file_path, file_content):\n",
    "    # 파일을 Base64로 인코딩\n",
    "    import base64\n",
    "    encoded_content = base64.b64encode(file_content.encode()).decode()\n",
    "\n",
    "    # 파일 커밋\n",
    "    data = {\n",
    "        \"message\": f\"Add test result file {file_path}\",\n",
    "        \"content\": encoded_content,\n",
    "        \"branch\": branch_name\n",
    "    }\n",
    "    response = requests.put(f\"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/contents/{file_path}\", headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 201:\n",
    "        print(f\"File '{file_path}' committed successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to commit file: {response.json()}\")\n",
    "\n",
    "# 3. PR 생성 함수\n",
    "def create_pull_request(branch_name):\n",
    "    data = {\n",
    "        \"title\": \"Add test result file\",\n",
    "        \"head\": branch_name,\n",
    "        \"base\": \"main\",\n",
    "        \"body\": \"This PR adds a new test result file.\"\n",
    "    }\n",
    "    response = requests.post(f\"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/pulls\", headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 201:\n",
    "        print(\"Pull request created successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to create pull request: {response.json()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need knowledge base and RAG\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool RAG\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_with_history_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    answer = chain.invoke({\"message\": message, \"history\": history_langchain_format})\n",
    "    \n",
    "    # Assign the result (answer) to the file_content\n",
    "    file_content = answer\n",
    "    branch_name = f\"test-result-{timestamp}\"\n",
    "    create_branch(branch_name)\n",
    "    commit_file(branch_name, file_path, file_content)\n",
    "    create_pull_request(branch_name)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.ChatInterface(\n",
    "        chat,\n",
    "        examples=[\n",
    "            \"How to eat healthy?\",\n",
    "            \"Best Places in Korea\",\n",
    "            \"How to make a chatbot?\",\n",
    "        ],\n",
    "        title=\"Solar Chatbot\",\n",
    "        description=\"Upstage Solar Chatbot\",\n",
    "    )\n",
    "    chatbot.chatbot.height = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'test-result-20240706151613' created successfully.\n",
      "File 'test/test-result-20240706151613.md' committed successfully.\n",
      "Pull request created successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
