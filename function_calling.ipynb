{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3293405d-c8eb-4399-b73b-f5d465efbc08",
   "metadata": {},
   "source": [
    "# Fuction Calling\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/function_calling.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "A function calling occurs when you interact with the Chat API to communicate with a Language Learning Model (LLM). Within the tool array, you have the flexibility to define custom functions. This capability enables the model to dynamically generate and provide function signatures in JSON format, facilitating seamless integration with external tools and applications.\n",
    "\n",
    "With function calling, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The model does not call the function, but it generates JSON that you can use to call the function in your code.\n",
    "\n",
    "1. Make assistant use external api.\n",
    "2. Call api with natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91916202-67af-4e51-b103-3cd437b09171",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cd73b-839a-4053-8531-8f9089b6e634",
   "metadata": {},
   "source": [
    "# Define API\n",
    "\n",
    "In this notebook, We'll define a dummy function that replaces the actual external API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed25955-abcd-45d2-a4c7-973b18c4fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"seoul\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276775d-9259-4dba-8fb8-67a8d200e451",
   "metadata": {},
   "source": [
    "# Run function calling\n",
    "\n",
    "In this example, we'll use function calling in the following order.\n",
    "\n",
    "1. Make an API call with tools parameter, which has function signature and description.\n",
    "2. API response contains tool calls\n",
    "3. Use it to call our function\n",
    "4. Make another API call with the response from our function appended to our original message list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05821b81-3605-4ae3-a95a-4db2fe07c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response message:\n",
      " [ChatCompletionMessageToolCall(id='119a29d5-ac04-4985-963e-4944060242e9', function=Function(arguments='{\"location\":\"San Francisco\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='3e319c52-1cec-42c0-9fb0-997b10780eaa', function=Function(arguments='{\"location\":\"Seoul\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='d6ea1dbc-467b-4704-a0b2-c9f952c4fb5f', function=Function(arguments='{\"location\":\"Paris\"}', name='get_current_weather'), type='function')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "upstage_api_key = \"\"\n",
    "client = OpenAI(api_key=upstage_api_key, base_url=\"https://api.upstage.ai/v1/solar\")\n",
    "\n",
    "# Define messages and tools\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in San Francisco, Seoul, and Paris?\",\n",
    "    }\n",
    "]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Request conversation and available functions to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "print(\"Response message:\\n\", response_message.tool_calls, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c31ca5-f09a-4e04-a075-7d35cd2c8033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages:\n",
      " [{'role': 'user', 'content': \"What's the weather like in San Francisco, Seoul, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='119a29d5-ac04-4985-963e-4944060242e9', function=Function(arguments='{\"location\":\"San Francisco\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='3e319c52-1cec-42c0-9fb0-997b10780eaa', function=Function(arguments='{\"location\":\"Seoul\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='d6ea1dbc-467b-4704-a0b2-c9f952c4fb5f', function=Function(arguments='{\"location\":\"Paris\"}', name='get_current_weather'), type='function')]), {'tool_call_id': '119a29d5-ac04-4985-963e-4944060242e9', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": null}'}, {'tool_call_id': '3e319c52-1cec-42c0-9fb0-997b10780eaa', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": null}'}, {'tool_call_id': 'd6ea1dbc-467b-4704-a0b2-c9f952c4fb5f', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": null}'}] \n",
      "\n",
      "The current weather in San Francisco is 72 degrees Fahrenheit, in Seoul is 10 degrees Celsius, and in Paris is 22 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "# Check if the model wanted to call a function and call the function\n",
    "if tool_calls:\n",
    "    available_function = {\n",
    "        \"get_current_weather\": get_current_weather\n",
    "    }\n",
    "    messages.append(response_message)\n",
    "\n",
    "    # Send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_function[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(location=function_args.get(\"location\"), unit=function_args.get(\"unit\"))\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response\n",
    "            }\n",
    "        )\n",
    "    print(\"messages:\\n\", messages, \"\\n\")\n",
    "    \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"solar-1-mini-chat\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(\"second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47341c90-87a7-4208-b4fa-5dd9d37e36e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
